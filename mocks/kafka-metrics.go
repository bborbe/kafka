// Code generated by counterfeiter. DO NOT EDIT.
package mocks

import (
	"sync"
	"time"

	"github.com/bborbe/kafka"
)

type KafkaMetrics struct {
	ConsumePartitionCreateFailureIncStub        func(kafka.Topic, kafka.Partition)
	consumePartitionCreateFailureIncMutex       sync.RWMutex
	consumePartitionCreateFailureIncArgsForCall []struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
	}
	ConsumePartitionCreateOutOfRangeErrorIncStub        func(kafka.Topic, kafka.Partition)
	consumePartitionCreateOutOfRangeErrorIncMutex       sync.RWMutex
	consumePartitionCreateOutOfRangeErrorIncArgsForCall []struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
	}
	ConsumePartitionCreateSuccessIncStub        func(kafka.Topic, kafka.Partition)
	consumePartitionCreateSuccessIncMutex       sync.RWMutex
	consumePartitionCreateSuccessIncArgsForCall []struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
	}
	ConsumePartitionCreateTotalIncStub        func(kafka.Topic, kafka.Partition)
	consumePartitionCreateTotalIncMutex       sync.RWMutex
	consumePartitionCreateTotalIncArgsForCall []struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
	}
	CurrentOffsetStub        func(kafka.Topic, kafka.Partition, kafka.Offset)
	currentOffsetMutex       sync.RWMutex
	currentOffsetArgsForCall []struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
		arg3 kafka.Offset
	}
	HighWaterMarkOffsetStub        func(kafka.Topic, kafka.Partition, kafka.Offset)
	highWaterMarkOffsetMutex       sync.RWMutex
	highWaterMarkOffsetArgsForCall []struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
		arg3 kafka.Offset
	}
	MessageHandlerDurationMeasureStub        func(kafka.Topic, kafka.Partition, time.Duration)
	messageHandlerDurationMeasureMutex       sync.RWMutex
	messageHandlerDurationMeasureArgsForCall []struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
		arg3 time.Duration
	}
	MessageHandlerFailureCounterIncStub        func(kafka.Topic, kafka.Partition)
	messageHandlerFailureCounterIncMutex       sync.RWMutex
	messageHandlerFailureCounterIncArgsForCall []struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
	}
	MessageHandlerSuccessCounterIncStub        func(kafka.Topic, kafka.Partition)
	messageHandlerSuccessCounterIncMutex       sync.RWMutex
	messageHandlerSuccessCounterIncArgsForCall []struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
	}
	MessageHandlerTotalCounterIncStub        func(kafka.Topic, kafka.Partition)
	messageHandlerTotalCounterIncMutex       sync.RWMutex
	messageHandlerTotalCounterIncArgsForCall []struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
	}
	SyncProducerDurationMeasureStub        func(kafka.Topic, time.Duration)
	syncProducerDurationMeasureMutex       sync.RWMutex
	syncProducerDurationMeasureArgsForCall []struct {
		arg1 kafka.Topic
		arg2 time.Duration
	}
	SyncProducerFailureCounterIncStub        func(kafka.Topic)
	syncProducerFailureCounterIncMutex       sync.RWMutex
	syncProducerFailureCounterIncArgsForCall []struct {
		arg1 kafka.Topic
	}
	SyncProducerSuccessCounterIncStub        func(kafka.Topic)
	syncProducerSuccessCounterIncMutex       sync.RWMutex
	syncProducerSuccessCounterIncArgsForCall []struct {
		arg1 kafka.Topic
	}
	SyncProducerTotalCounterIncStub        func(kafka.Topic)
	syncProducerTotalCounterIncMutex       sync.RWMutex
	syncProducerTotalCounterIncArgsForCall []struct {
		arg1 kafka.Topic
	}
	invocations      map[string][][]interface{}
	invocationsMutex sync.RWMutex
}

func (fake *KafkaMetrics) ConsumePartitionCreateFailureInc(arg1 kafka.Topic, arg2 kafka.Partition) {
	fake.consumePartitionCreateFailureIncMutex.Lock()
	fake.consumePartitionCreateFailureIncArgsForCall = append(fake.consumePartitionCreateFailureIncArgsForCall, struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
	}{arg1, arg2})
	stub := fake.ConsumePartitionCreateFailureIncStub
	fake.recordInvocation("ConsumePartitionCreateFailureInc", []interface{}{arg1, arg2})
	fake.consumePartitionCreateFailureIncMutex.Unlock()
	if stub != nil {
		fake.ConsumePartitionCreateFailureIncStub(arg1, arg2)
	}
}

func (fake *KafkaMetrics) ConsumePartitionCreateFailureIncCallCount() int {
	fake.consumePartitionCreateFailureIncMutex.RLock()
	defer fake.consumePartitionCreateFailureIncMutex.RUnlock()
	return len(fake.consumePartitionCreateFailureIncArgsForCall)
}

func (fake *KafkaMetrics) ConsumePartitionCreateFailureIncCalls(stub func(kafka.Topic, kafka.Partition)) {
	fake.consumePartitionCreateFailureIncMutex.Lock()
	defer fake.consumePartitionCreateFailureIncMutex.Unlock()
	fake.ConsumePartitionCreateFailureIncStub = stub
}

func (fake *KafkaMetrics) ConsumePartitionCreateFailureIncArgsForCall(i int) (kafka.Topic, kafka.Partition) {
	fake.consumePartitionCreateFailureIncMutex.RLock()
	defer fake.consumePartitionCreateFailureIncMutex.RUnlock()
	argsForCall := fake.consumePartitionCreateFailureIncArgsForCall[i]
	return argsForCall.arg1, argsForCall.arg2
}

func (fake *KafkaMetrics) ConsumePartitionCreateOutOfRangeErrorInc(arg1 kafka.Topic, arg2 kafka.Partition) {
	fake.consumePartitionCreateOutOfRangeErrorIncMutex.Lock()
	fake.consumePartitionCreateOutOfRangeErrorIncArgsForCall = append(fake.consumePartitionCreateOutOfRangeErrorIncArgsForCall, struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
	}{arg1, arg2})
	stub := fake.ConsumePartitionCreateOutOfRangeErrorIncStub
	fake.recordInvocation("ConsumePartitionCreateOutOfRangeErrorInc", []interface{}{arg1, arg2})
	fake.consumePartitionCreateOutOfRangeErrorIncMutex.Unlock()
	if stub != nil {
		fake.ConsumePartitionCreateOutOfRangeErrorIncStub(arg1, arg2)
	}
}

func (fake *KafkaMetrics) ConsumePartitionCreateOutOfRangeErrorIncCallCount() int {
	fake.consumePartitionCreateOutOfRangeErrorIncMutex.RLock()
	defer fake.consumePartitionCreateOutOfRangeErrorIncMutex.RUnlock()
	return len(fake.consumePartitionCreateOutOfRangeErrorIncArgsForCall)
}

func (fake *KafkaMetrics) ConsumePartitionCreateOutOfRangeErrorIncCalls(stub func(kafka.Topic, kafka.Partition)) {
	fake.consumePartitionCreateOutOfRangeErrorIncMutex.Lock()
	defer fake.consumePartitionCreateOutOfRangeErrorIncMutex.Unlock()
	fake.ConsumePartitionCreateOutOfRangeErrorIncStub = stub
}

func (fake *KafkaMetrics) ConsumePartitionCreateOutOfRangeErrorIncArgsForCall(i int) (kafka.Topic, kafka.Partition) {
	fake.consumePartitionCreateOutOfRangeErrorIncMutex.RLock()
	defer fake.consumePartitionCreateOutOfRangeErrorIncMutex.RUnlock()
	argsForCall := fake.consumePartitionCreateOutOfRangeErrorIncArgsForCall[i]
	return argsForCall.arg1, argsForCall.arg2
}

func (fake *KafkaMetrics) ConsumePartitionCreateSuccessInc(arg1 kafka.Topic, arg2 kafka.Partition) {
	fake.consumePartitionCreateSuccessIncMutex.Lock()
	fake.consumePartitionCreateSuccessIncArgsForCall = append(fake.consumePartitionCreateSuccessIncArgsForCall, struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
	}{arg1, arg2})
	stub := fake.ConsumePartitionCreateSuccessIncStub
	fake.recordInvocation("ConsumePartitionCreateSuccessInc", []interface{}{arg1, arg2})
	fake.consumePartitionCreateSuccessIncMutex.Unlock()
	if stub != nil {
		fake.ConsumePartitionCreateSuccessIncStub(arg1, arg2)
	}
}

func (fake *KafkaMetrics) ConsumePartitionCreateSuccessIncCallCount() int {
	fake.consumePartitionCreateSuccessIncMutex.RLock()
	defer fake.consumePartitionCreateSuccessIncMutex.RUnlock()
	return len(fake.consumePartitionCreateSuccessIncArgsForCall)
}

func (fake *KafkaMetrics) ConsumePartitionCreateSuccessIncCalls(stub func(kafka.Topic, kafka.Partition)) {
	fake.consumePartitionCreateSuccessIncMutex.Lock()
	defer fake.consumePartitionCreateSuccessIncMutex.Unlock()
	fake.ConsumePartitionCreateSuccessIncStub = stub
}

func (fake *KafkaMetrics) ConsumePartitionCreateSuccessIncArgsForCall(i int) (kafka.Topic, kafka.Partition) {
	fake.consumePartitionCreateSuccessIncMutex.RLock()
	defer fake.consumePartitionCreateSuccessIncMutex.RUnlock()
	argsForCall := fake.consumePartitionCreateSuccessIncArgsForCall[i]
	return argsForCall.arg1, argsForCall.arg2
}

func (fake *KafkaMetrics) ConsumePartitionCreateTotalInc(arg1 kafka.Topic, arg2 kafka.Partition) {
	fake.consumePartitionCreateTotalIncMutex.Lock()
	fake.consumePartitionCreateTotalIncArgsForCall = append(fake.consumePartitionCreateTotalIncArgsForCall, struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
	}{arg1, arg2})
	stub := fake.ConsumePartitionCreateTotalIncStub
	fake.recordInvocation("ConsumePartitionCreateTotalInc", []interface{}{arg1, arg2})
	fake.consumePartitionCreateTotalIncMutex.Unlock()
	if stub != nil {
		fake.ConsumePartitionCreateTotalIncStub(arg1, arg2)
	}
}

func (fake *KafkaMetrics) ConsumePartitionCreateTotalIncCallCount() int {
	fake.consumePartitionCreateTotalIncMutex.RLock()
	defer fake.consumePartitionCreateTotalIncMutex.RUnlock()
	return len(fake.consumePartitionCreateTotalIncArgsForCall)
}

func (fake *KafkaMetrics) ConsumePartitionCreateTotalIncCalls(stub func(kafka.Topic, kafka.Partition)) {
	fake.consumePartitionCreateTotalIncMutex.Lock()
	defer fake.consumePartitionCreateTotalIncMutex.Unlock()
	fake.ConsumePartitionCreateTotalIncStub = stub
}

func (fake *KafkaMetrics) ConsumePartitionCreateTotalIncArgsForCall(i int) (kafka.Topic, kafka.Partition) {
	fake.consumePartitionCreateTotalIncMutex.RLock()
	defer fake.consumePartitionCreateTotalIncMutex.RUnlock()
	argsForCall := fake.consumePartitionCreateTotalIncArgsForCall[i]
	return argsForCall.arg1, argsForCall.arg2
}

func (fake *KafkaMetrics) CurrentOffset(arg1 kafka.Topic, arg2 kafka.Partition, arg3 kafka.Offset) {
	fake.currentOffsetMutex.Lock()
	fake.currentOffsetArgsForCall = append(fake.currentOffsetArgsForCall, struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
		arg3 kafka.Offset
	}{arg1, arg2, arg3})
	stub := fake.CurrentOffsetStub
	fake.recordInvocation("CurrentOffset", []interface{}{arg1, arg2, arg3})
	fake.currentOffsetMutex.Unlock()
	if stub != nil {
		fake.CurrentOffsetStub(arg1, arg2, arg3)
	}
}

func (fake *KafkaMetrics) CurrentOffsetCallCount() int {
	fake.currentOffsetMutex.RLock()
	defer fake.currentOffsetMutex.RUnlock()
	return len(fake.currentOffsetArgsForCall)
}

func (fake *KafkaMetrics) CurrentOffsetCalls(stub func(kafka.Topic, kafka.Partition, kafka.Offset)) {
	fake.currentOffsetMutex.Lock()
	defer fake.currentOffsetMutex.Unlock()
	fake.CurrentOffsetStub = stub
}

func (fake *KafkaMetrics) CurrentOffsetArgsForCall(i int) (kafka.Topic, kafka.Partition, kafka.Offset) {
	fake.currentOffsetMutex.RLock()
	defer fake.currentOffsetMutex.RUnlock()
	argsForCall := fake.currentOffsetArgsForCall[i]
	return argsForCall.arg1, argsForCall.arg2, argsForCall.arg3
}

func (fake *KafkaMetrics) HighWaterMarkOffset(arg1 kafka.Topic, arg2 kafka.Partition, arg3 kafka.Offset) {
	fake.highWaterMarkOffsetMutex.Lock()
	fake.highWaterMarkOffsetArgsForCall = append(fake.highWaterMarkOffsetArgsForCall, struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
		arg3 kafka.Offset
	}{arg1, arg2, arg3})
	stub := fake.HighWaterMarkOffsetStub
	fake.recordInvocation("HighWaterMarkOffset", []interface{}{arg1, arg2, arg3})
	fake.highWaterMarkOffsetMutex.Unlock()
	if stub != nil {
		fake.HighWaterMarkOffsetStub(arg1, arg2, arg3)
	}
}

func (fake *KafkaMetrics) HighWaterMarkOffsetCallCount() int {
	fake.highWaterMarkOffsetMutex.RLock()
	defer fake.highWaterMarkOffsetMutex.RUnlock()
	return len(fake.highWaterMarkOffsetArgsForCall)
}

func (fake *KafkaMetrics) HighWaterMarkOffsetCalls(stub func(kafka.Topic, kafka.Partition, kafka.Offset)) {
	fake.highWaterMarkOffsetMutex.Lock()
	defer fake.highWaterMarkOffsetMutex.Unlock()
	fake.HighWaterMarkOffsetStub = stub
}

func (fake *KafkaMetrics) HighWaterMarkOffsetArgsForCall(i int) (kafka.Topic, kafka.Partition, kafka.Offset) {
	fake.highWaterMarkOffsetMutex.RLock()
	defer fake.highWaterMarkOffsetMutex.RUnlock()
	argsForCall := fake.highWaterMarkOffsetArgsForCall[i]
	return argsForCall.arg1, argsForCall.arg2, argsForCall.arg3
}

func (fake *KafkaMetrics) MessageHandlerDurationMeasure(arg1 kafka.Topic, arg2 kafka.Partition, arg3 time.Duration) {
	fake.messageHandlerDurationMeasureMutex.Lock()
	fake.messageHandlerDurationMeasureArgsForCall = append(fake.messageHandlerDurationMeasureArgsForCall, struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
		arg3 time.Duration
	}{arg1, arg2, arg3})
	stub := fake.MessageHandlerDurationMeasureStub
	fake.recordInvocation("MessageHandlerDurationMeasure", []interface{}{arg1, arg2, arg3})
	fake.messageHandlerDurationMeasureMutex.Unlock()
	if stub != nil {
		fake.MessageHandlerDurationMeasureStub(arg1, arg2, arg3)
	}
}

func (fake *KafkaMetrics) MessageHandlerDurationMeasureCallCount() int {
	fake.messageHandlerDurationMeasureMutex.RLock()
	defer fake.messageHandlerDurationMeasureMutex.RUnlock()
	return len(fake.messageHandlerDurationMeasureArgsForCall)
}

func (fake *KafkaMetrics) MessageHandlerDurationMeasureCalls(stub func(kafka.Topic, kafka.Partition, time.Duration)) {
	fake.messageHandlerDurationMeasureMutex.Lock()
	defer fake.messageHandlerDurationMeasureMutex.Unlock()
	fake.MessageHandlerDurationMeasureStub = stub
}

func (fake *KafkaMetrics) MessageHandlerDurationMeasureArgsForCall(i int) (kafka.Topic, kafka.Partition, time.Duration) {
	fake.messageHandlerDurationMeasureMutex.RLock()
	defer fake.messageHandlerDurationMeasureMutex.RUnlock()
	argsForCall := fake.messageHandlerDurationMeasureArgsForCall[i]
	return argsForCall.arg1, argsForCall.arg2, argsForCall.arg3
}

func (fake *KafkaMetrics) MessageHandlerFailureCounterInc(arg1 kafka.Topic, arg2 kafka.Partition) {
	fake.messageHandlerFailureCounterIncMutex.Lock()
	fake.messageHandlerFailureCounterIncArgsForCall = append(fake.messageHandlerFailureCounterIncArgsForCall, struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
	}{arg1, arg2})
	stub := fake.MessageHandlerFailureCounterIncStub
	fake.recordInvocation("MessageHandlerFailureCounterInc", []interface{}{arg1, arg2})
	fake.messageHandlerFailureCounterIncMutex.Unlock()
	if stub != nil {
		fake.MessageHandlerFailureCounterIncStub(arg1, arg2)
	}
}

func (fake *KafkaMetrics) MessageHandlerFailureCounterIncCallCount() int {
	fake.messageHandlerFailureCounterIncMutex.RLock()
	defer fake.messageHandlerFailureCounterIncMutex.RUnlock()
	return len(fake.messageHandlerFailureCounterIncArgsForCall)
}

func (fake *KafkaMetrics) MessageHandlerFailureCounterIncCalls(stub func(kafka.Topic, kafka.Partition)) {
	fake.messageHandlerFailureCounterIncMutex.Lock()
	defer fake.messageHandlerFailureCounterIncMutex.Unlock()
	fake.MessageHandlerFailureCounterIncStub = stub
}

func (fake *KafkaMetrics) MessageHandlerFailureCounterIncArgsForCall(i int) (kafka.Topic, kafka.Partition) {
	fake.messageHandlerFailureCounterIncMutex.RLock()
	defer fake.messageHandlerFailureCounterIncMutex.RUnlock()
	argsForCall := fake.messageHandlerFailureCounterIncArgsForCall[i]
	return argsForCall.arg1, argsForCall.arg2
}

func (fake *KafkaMetrics) MessageHandlerSuccessCounterInc(arg1 kafka.Topic, arg2 kafka.Partition) {
	fake.messageHandlerSuccessCounterIncMutex.Lock()
	fake.messageHandlerSuccessCounterIncArgsForCall = append(fake.messageHandlerSuccessCounterIncArgsForCall, struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
	}{arg1, arg2})
	stub := fake.MessageHandlerSuccessCounterIncStub
	fake.recordInvocation("MessageHandlerSuccessCounterInc", []interface{}{arg1, arg2})
	fake.messageHandlerSuccessCounterIncMutex.Unlock()
	if stub != nil {
		fake.MessageHandlerSuccessCounterIncStub(arg1, arg2)
	}
}

func (fake *KafkaMetrics) MessageHandlerSuccessCounterIncCallCount() int {
	fake.messageHandlerSuccessCounterIncMutex.RLock()
	defer fake.messageHandlerSuccessCounterIncMutex.RUnlock()
	return len(fake.messageHandlerSuccessCounterIncArgsForCall)
}

func (fake *KafkaMetrics) MessageHandlerSuccessCounterIncCalls(stub func(kafka.Topic, kafka.Partition)) {
	fake.messageHandlerSuccessCounterIncMutex.Lock()
	defer fake.messageHandlerSuccessCounterIncMutex.Unlock()
	fake.MessageHandlerSuccessCounterIncStub = stub
}

func (fake *KafkaMetrics) MessageHandlerSuccessCounterIncArgsForCall(i int) (kafka.Topic, kafka.Partition) {
	fake.messageHandlerSuccessCounterIncMutex.RLock()
	defer fake.messageHandlerSuccessCounterIncMutex.RUnlock()
	argsForCall := fake.messageHandlerSuccessCounterIncArgsForCall[i]
	return argsForCall.arg1, argsForCall.arg2
}

func (fake *KafkaMetrics) MessageHandlerTotalCounterInc(arg1 kafka.Topic, arg2 kafka.Partition) {
	fake.messageHandlerTotalCounterIncMutex.Lock()
	fake.messageHandlerTotalCounterIncArgsForCall = append(fake.messageHandlerTotalCounterIncArgsForCall, struct {
		arg1 kafka.Topic
		arg2 kafka.Partition
	}{arg1, arg2})
	stub := fake.MessageHandlerTotalCounterIncStub
	fake.recordInvocation("MessageHandlerTotalCounterInc", []interface{}{arg1, arg2})
	fake.messageHandlerTotalCounterIncMutex.Unlock()
	if stub != nil {
		fake.MessageHandlerTotalCounterIncStub(arg1, arg2)
	}
}

func (fake *KafkaMetrics) MessageHandlerTotalCounterIncCallCount() int {
	fake.messageHandlerTotalCounterIncMutex.RLock()
	defer fake.messageHandlerTotalCounterIncMutex.RUnlock()
	return len(fake.messageHandlerTotalCounterIncArgsForCall)
}

func (fake *KafkaMetrics) MessageHandlerTotalCounterIncCalls(stub func(kafka.Topic, kafka.Partition)) {
	fake.messageHandlerTotalCounterIncMutex.Lock()
	defer fake.messageHandlerTotalCounterIncMutex.Unlock()
	fake.MessageHandlerTotalCounterIncStub = stub
}

func (fake *KafkaMetrics) MessageHandlerTotalCounterIncArgsForCall(i int) (kafka.Topic, kafka.Partition) {
	fake.messageHandlerTotalCounterIncMutex.RLock()
	defer fake.messageHandlerTotalCounterIncMutex.RUnlock()
	argsForCall := fake.messageHandlerTotalCounterIncArgsForCall[i]
	return argsForCall.arg1, argsForCall.arg2
}

func (fake *KafkaMetrics) SyncProducerDurationMeasure(arg1 kafka.Topic, arg2 time.Duration) {
	fake.syncProducerDurationMeasureMutex.Lock()
	fake.syncProducerDurationMeasureArgsForCall = append(fake.syncProducerDurationMeasureArgsForCall, struct {
		arg1 kafka.Topic
		arg2 time.Duration
	}{arg1, arg2})
	stub := fake.SyncProducerDurationMeasureStub
	fake.recordInvocation("SyncProducerDurationMeasure", []interface{}{arg1, arg2})
	fake.syncProducerDurationMeasureMutex.Unlock()
	if stub != nil {
		fake.SyncProducerDurationMeasureStub(arg1, arg2)
	}
}

func (fake *KafkaMetrics) SyncProducerDurationMeasureCallCount() int {
	fake.syncProducerDurationMeasureMutex.RLock()
	defer fake.syncProducerDurationMeasureMutex.RUnlock()
	return len(fake.syncProducerDurationMeasureArgsForCall)
}

func (fake *KafkaMetrics) SyncProducerDurationMeasureCalls(stub func(kafka.Topic, time.Duration)) {
	fake.syncProducerDurationMeasureMutex.Lock()
	defer fake.syncProducerDurationMeasureMutex.Unlock()
	fake.SyncProducerDurationMeasureStub = stub
}

func (fake *KafkaMetrics) SyncProducerDurationMeasureArgsForCall(i int) (kafka.Topic, time.Duration) {
	fake.syncProducerDurationMeasureMutex.RLock()
	defer fake.syncProducerDurationMeasureMutex.RUnlock()
	argsForCall := fake.syncProducerDurationMeasureArgsForCall[i]
	return argsForCall.arg1, argsForCall.arg2
}

func (fake *KafkaMetrics) SyncProducerFailureCounterInc(arg1 kafka.Topic) {
	fake.syncProducerFailureCounterIncMutex.Lock()
	fake.syncProducerFailureCounterIncArgsForCall = append(fake.syncProducerFailureCounterIncArgsForCall, struct {
		arg1 kafka.Topic
	}{arg1})
	stub := fake.SyncProducerFailureCounterIncStub
	fake.recordInvocation("SyncProducerFailureCounterInc", []interface{}{arg1})
	fake.syncProducerFailureCounterIncMutex.Unlock()
	if stub != nil {
		fake.SyncProducerFailureCounterIncStub(arg1)
	}
}

func (fake *KafkaMetrics) SyncProducerFailureCounterIncCallCount() int {
	fake.syncProducerFailureCounterIncMutex.RLock()
	defer fake.syncProducerFailureCounterIncMutex.RUnlock()
	return len(fake.syncProducerFailureCounterIncArgsForCall)
}

func (fake *KafkaMetrics) SyncProducerFailureCounterIncCalls(stub func(kafka.Topic)) {
	fake.syncProducerFailureCounterIncMutex.Lock()
	defer fake.syncProducerFailureCounterIncMutex.Unlock()
	fake.SyncProducerFailureCounterIncStub = stub
}

func (fake *KafkaMetrics) SyncProducerFailureCounterIncArgsForCall(i int) kafka.Topic {
	fake.syncProducerFailureCounterIncMutex.RLock()
	defer fake.syncProducerFailureCounterIncMutex.RUnlock()
	argsForCall := fake.syncProducerFailureCounterIncArgsForCall[i]
	return argsForCall.arg1
}

func (fake *KafkaMetrics) SyncProducerSuccessCounterInc(arg1 kafka.Topic) {
	fake.syncProducerSuccessCounterIncMutex.Lock()
	fake.syncProducerSuccessCounterIncArgsForCall = append(fake.syncProducerSuccessCounterIncArgsForCall, struct {
		arg1 kafka.Topic
	}{arg1})
	stub := fake.SyncProducerSuccessCounterIncStub
	fake.recordInvocation("SyncProducerSuccessCounterInc", []interface{}{arg1})
	fake.syncProducerSuccessCounterIncMutex.Unlock()
	if stub != nil {
		fake.SyncProducerSuccessCounterIncStub(arg1)
	}
}

func (fake *KafkaMetrics) SyncProducerSuccessCounterIncCallCount() int {
	fake.syncProducerSuccessCounterIncMutex.RLock()
	defer fake.syncProducerSuccessCounterIncMutex.RUnlock()
	return len(fake.syncProducerSuccessCounterIncArgsForCall)
}

func (fake *KafkaMetrics) SyncProducerSuccessCounterIncCalls(stub func(kafka.Topic)) {
	fake.syncProducerSuccessCounterIncMutex.Lock()
	defer fake.syncProducerSuccessCounterIncMutex.Unlock()
	fake.SyncProducerSuccessCounterIncStub = stub
}

func (fake *KafkaMetrics) SyncProducerSuccessCounterIncArgsForCall(i int) kafka.Topic {
	fake.syncProducerSuccessCounterIncMutex.RLock()
	defer fake.syncProducerSuccessCounterIncMutex.RUnlock()
	argsForCall := fake.syncProducerSuccessCounterIncArgsForCall[i]
	return argsForCall.arg1
}

func (fake *KafkaMetrics) SyncProducerTotalCounterInc(arg1 kafka.Topic) {
	fake.syncProducerTotalCounterIncMutex.Lock()
	fake.syncProducerTotalCounterIncArgsForCall = append(fake.syncProducerTotalCounterIncArgsForCall, struct {
		arg1 kafka.Topic
	}{arg1})
	stub := fake.SyncProducerTotalCounterIncStub
	fake.recordInvocation("SyncProducerTotalCounterInc", []interface{}{arg1})
	fake.syncProducerTotalCounterIncMutex.Unlock()
	if stub != nil {
		fake.SyncProducerTotalCounterIncStub(arg1)
	}
}

func (fake *KafkaMetrics) SyncProducerTotalCounterIncCallCount() int {
	fake.syncProducerTotalCounterIncMutex.RLock()
	defer fake.syncProducerTotalCounterIncMutex.RUnlock()
	return len(fake.syncProducerTotalCounterIncArgsForCall)
}

func (fake *KafkaMetrics) SyncProducerTotalCounterIncCalls(stub func(kafka.Topic)) {
	fake.syncProducerTotalCounterIncMutex.Lock()
	defer fake.syncProducerTotalCounterIncMutex.Unlock()
	fake.SyncProducerTotalCounterIncStub = stub
}

func (fake *KafkaMetrics) SyncProducerTotalCounterIncArgsForCall(i int) kafka.Topic {
	fake.syncProducerTotalCounterIncMutex.RLock()
	defer fake.syncProducerTotalCounterIncMutex.RUnlock()
	argsForCall := fake.syncProducerTotalCounterIncArgsForCall[i]
	return argsForCall.arg1
}

func (fake *KafkaMetrics) Invocations() map[string][][]interface{} {
	fake.invocationsMutex.RLock()
	defer fake.invocationsMutex.RUnlock()
	fake.consumePartitionCreateFailureIncMutex.RLock()
	defer fake.consumePartitionCreateFailureIncMutex.RUnlock()
	fake.consumePartitionCreateOutOfRangeErrorIncMutex.RLock()
	defer fake.consumePartitionCreateOutOfRangeErrorIncMutex.RUnlock()
	fake.consumePartitionCreateSuccessIncMutex.RLock()
	defer fake.consumePartitionCreateSuccessIncMutex.RUnlock()
	fake.consumePartitionCreateTotalIncMutex.RLock()
	defer fake.consumePartitionCreateTotalIncMutex.RUnlock()
	fake.currentOffsetMutex.RLock()
	defer fake.currentOffsetMutex.RUnlock()
	fake.highWaterMarkOffsetMutex.RLock()
	defer fake.highWaterMarkOffsetMutex.RUnlock()
	fake.messageHandlerDurationMeasureMutex.RLock()
	defer fake.messageHandlerDurationMeasureMutex.RUnlock()
	fake.messageHandlerFailureCounterIncMutex.RLock()
	defer fake.messageHandlerFailureCounterIncMutex.RUnlock()
	fake.messageHandlerSuccessCounterIncMutex.RLock()
	defer fake.messageHandlerSuccessCounterIncMutex.RUnlock()
	fake.messageHandlerTotalCounterIncMutex.RLock()
	defer fake.messageHandlerTotalCounterIncMutex.RUnlock()
	fake.syncProducerDurationMeasureMutex.RLock()
	defer fake.syncProducerDurationMeasureMutex.RUnlock()
	fake.syncProducerFailureCounterIncMutex.RLock()
	defer fake.syncProducerFailureCounterIncMutex.RUnlock()
	fake.syncProducerSuccessCounterIncMutex.RLock()
	defer fake.syncProducerSuccessCounterIncMutex.RUnlock()
	fake.syncProducerTotalCounterIncMutex.RLock()
	defer fake.syncProducerTotalCounterIncMutex.RUnlock()
	copiedInvocations := map[string][][]interface{}{}
	for key, value := range fake.invocations {
		copiedInvocations[key] = value
	}
	return copiedInvocations
}

func (fake *KafkaMetrics) recordInvocation(key string, args []interface{}) {
	fake.invocationsMutex.Lock()
	defer fake.invocationsMutex.Unlock()
	if fake.invocations == nil {
		fake.invocations = map[string][][]interface{}{}
	}
	if fake.invocations[key] == nil {
		fake.invocations[key] = [][]interface{}{}
	}
	fake.invocations[key] = append(fake.invocations[key], args)
}

var _ kafka.Metrics = new(KafkaMetrics)
